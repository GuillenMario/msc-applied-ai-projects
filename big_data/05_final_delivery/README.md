# ğŸ“¦ Final Delivery: Data Science Project with PySpark and Python

This notebook represents the **final delivery** of the project, integrating data preprocessing, modeling, metric computation, and visualization into a comprehensive workflow.

## ğŸš€ Project Overview

The goal of this notebook is to:

- Deliver final results including **Accuracy**.

- Deliver final results including **F1**.

- Deliver final results including **Recall**.

- Provide clear visualizations and interpretations of results.


## ğŸ“Š Workflow Steps

### 1. Data Integration
- Import and preprocess datasets.
- Ensure consistency and quality of data for modeling.

### 2. Modeling
- Train and evaluate models (supervised and/or unsupervised).
- Apply hyperparameter tuning where needed.

### 3. Metrics & Evaluation
- Compute evaluation metrics for final models.
- Summarize results in tables and figures.

### 4. Visualization & Interpretation
- Generate plots for insights.
- Provide narrative on model performance and implications.


## ğŸ›  Technologies

- Python 3.x
- PySpark / Apache Spark
- pandas
- matplotlib / seaborn
- scikit-learn

## ğŸ“Œ Key Results

- Implemented functions: categorical_summary, plot_multiclass_auc_bars, plot_multiclass_roc_all_folds, print_heatmap

- Final metrics delivered: Accuracy, F1, Recall.

- Visualizations provide stakeholders with clear insights.

## ğŸ‘¨â€ğŸ“ Author

Mario Alberto Guillen De La Torre

---
