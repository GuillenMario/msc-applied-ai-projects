# ğŸ“Š Results Visualization with PySpark and Python

This notebook focuses on **visualizing model and data quality metrics**. It leverages PySpark, pandas, and visualization libraries to provide clear, interpretable plots of results.

## ğŸš€ Project Overview

The goal of this notebook is to:

- Visualize **Accuracy**.

- Visualize **F1**.

- Visualize **Recall**.

- Visualize **Silhouette**.


## ğŸ“Š Workflow Steps

### 1. Data Loading & Preparation
- Import results from previous modeling steps.
- Format data for visualization.

### 2. Visualization
- Generate plots using matplotlib, seaborn, and/or plotly.
- Compare models and highlight performance.

### 3. Interpretation
- Document insights from each visualization.


## ğŸ›  Technologies

- Python 3.x
- PySpark / Apache Spark
- pandas
- matplotlib / seaborn
- scikit-learn

## ğŸ“Œ Key Results

- Implemented functions: categorical_summary, plot_multiclass_auc_bars, plot_multiclass_roc_all_folds, print_heatmap

- Metrics visualized: Accuracy, F1, Recall, Silhouette.

- Provides clear dashboards and plots to understand model performance.

## ğŸ‘¨â€ğŸ“ Author

Mario Alberto Guillen De La Torre

---
