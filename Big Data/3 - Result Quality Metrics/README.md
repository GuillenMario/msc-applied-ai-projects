# 📊 Result Quality Metrics with PySpark and Python

This notebook demonstrates the computation and visualization of **quality metrics** for evaluating machine learning and data science results. It integrates PySpark, pandas, and visualization libraries for assessing model and clustering performance.

## 🚀 Project Overview

The goal of this notebook is to:

- Compute and analyze **Recall**.

- Compute and analyze **Rmse**.

- Compute and analyze **Silhouette**.


## 📊 Workflow Steps

### 1. Data Preparation

- Load dataset(s) into Spark and/or pandas DataFrames.
- Clean and preprocess the data for further analysis.

### 2. Metric Computation

- Apply statistical and ML metrics to evaluate predictions.
- Metrics include regression (RMSE, MAE, R²), classification (Accuracy, Precision, Recall, F1, AUC), and clustering (Silhouette, Davies-Bouldin, Calinski-Harabasz).

### 3. Visualization

- Use matplotlib/seaborn/plotly to visualize performance metrics.
- Highlight strengths, weaknesses, and potential improvements.

### 4. Interpretation

- Document the meaning of each metric.
- Provide guidance for improving model performance.


## 🛠 Technologies

- Python 3.x
- PySpark / Apache Spark
- pandas
- matplotlib / seaborn

## 📌 Key Results

- Implemented functions: pretty_display, remove_outliers_inplace

- Metrics evaluated: Recall, Rmse, Silhouette.

- Visualizations help identify performance gaps and model improvement opportunities.

## 👨‍🎓 Author

Mario Alberto Guillen De La Torre

---
